# test-pipeline.yaml
# - GitHub Actions 테스트 파이프라인의 구조를 설명하기 위한 템플릿
# - 실제 구현은 .github/workflows/test-pipeline.yml 을 참고
name: Test Agent

on:
  # Agent/테스트/스크립트 변경 시 자동으로 테스트 파이프라인 실행
  push:
    branches: [main, develop]
    paths:
      - 'agents/**'
      - 'tests/**'
      - 'scripts/**'
  pull_request:
    branches: [main]
    paths:
      - 'agents/**'
      - 'tests/**'
      - 'scripts/**'
  workflow_dispatch:        # 필요 시 수동 실행

env:
  PYTHON_VERSION: '3.11'

jobs:
  unit-test:
    # Job 1: Python 단위 테스트 + 프롬프트 렌더링 테스트
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Unit Tests       # tests/unit/** 실행
        run: |
          pytest tests/unit/ -v --cov=scripts --cov-report=xml
      
      - name: Test Prompt Rendering  # 템플릿 치환 테스트
        run: |
          python scripts/test-prompt-rendering.py
      
      - name: Upload Coverage       # 커버리지 리포트 업로드
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  integration-test:
    # Job 2: 통합 테스트 (필요 시 임시 테스트 환경 배포 후 테스트)
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Configure AWS credentials   # (선택) 테스트 환경이 AWS 리소스를 사용할 때
        if: env.AWS_ACCESS_KEY_ID != ''
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Deploy Test Environment     # 주석된 예시는 Terraform 기반 배포 예시
        run: |
          echo "Deploying test environment..."
          # 테스트 환경 배포 로직 (예: Terraform, AWS CLI 등)
          # terraform apply -auto-approve -var="environment=test"
      
      - name: Run Integration Tests       # tests/integration/** 실행
        run: |
          pytest tests/integration/ -v
        env:
          TEST_ENVIRONMENT: test
      
      - name: Cleanup Test Environment    # 항상 실행하여 임시 리소스 정리
        if: always()
        run: |
          echo "Cleaning up test environment..."
          # terraform destroy -auto-approve -var="environment=test"

  evaluation:
    # Job 3: 평가 데이터셋 기반 자동 평가
    name: Evaluation Tests
    runs-on: ubuntu-latest
    needs: integration-test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Configure AWS credentials   # Agent 호출이 클라우드에 의존할 경우
        if: env.AWS_ACCESS_KEY_ID != ''
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Run Evaluation              # 예시: agents/*/evaluation-dataset.json을 순회 평가
        run: |
          for agent_dir in agents/*/; do
            agent_name=$(basename "$agent_dir")
            dataset_file="$agent_dir/tests/evaluation-dataset.json"
            if [ -f "$dataset_file" ]; then
              echo "Running evaluation for agent: $agent_name"
              python scripts/run-evaluation.py \
                --dataset "$dataset_file" \
                --agent "$agent_dir"
            fi
          done
      
      - name: Generate Evaluation Report  # 요약 리포트 생성
        run: |
          python scripts/generate-evaluation-report.py
      
      - name: Upload Evaluation Results   # 평가 결과 업로드
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-results
          path: evaluation-results/
          retention-days: 30
